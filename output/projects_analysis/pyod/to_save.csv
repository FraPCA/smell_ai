filename,function_name,smell,name_smell,message
/Users/broke31/Desktop/smell_ai/input/projects/pyod/examples/temp_do_not_use.py,_train_autoencoder,1,gradients_not_cleared_before_backward_propagation,"If optimizer.zero_grad() is not used before loss_- fn.backward(), the gradients will be accumulatedfrom all loss_- fn.backward() calls and it will lead to the gradient explosion,which fails the training."
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/rgraph.py,active_support_elastic_net,5,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/rgraph.py,elastic_net_subspace_clustering,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/mo_gaal.py,fit,1,memory_not_freed,Memory not freed
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/sod.py,_sod,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/rod.py,angle,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/rod.py,rod_3D,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/abod.py,_wcos,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/loda.py,fit,2,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/loda.py,decision_function,2,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/kpca.py,decision_function,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/sos.py,_x2d,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/auto_encoder_torch.py,_train_autoencoder,1,gradients_not_cleared_before_backward_propagation,"If optimizer.zero_grad() is not used before loss_- fn.backward(), the gradients will be accumulatedfrom all loss_- fn.backward() calls and it will lead to the gradient explosion,which fails the training."
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/lunar.py,fit,1,gradients_not_cleared_before_backward_propagation,"If optimizer.zero_grad() is not used before loss_- fn.backward(), the gradients will be accumulatedfrom all loss_- fn.backward() calls and it will lead to the gradient explosion,which fails the training."
/Users/broke31/Desktop/smell_ai/input/projects/pyod/pyod/models/cd.py,Cooks_dist,1,matrix_multiplication_api_misused,"Please consider to use np.matmul to multiply matrix. The function dot() not return a scalar value, but a matrix. "
